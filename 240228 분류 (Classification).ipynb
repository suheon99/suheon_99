{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e6dc63",
   "metadata": {},
   "source": [
    "### 이중 분류 (Binary Classification)\n",
    "\n",
    "- **정의**: 데이터 포인트를 두 개의 그룹(예: 예/아니오, 참/거짓) 중 하나로 분류하는 과정\n",
    "- **예시**: 이메일이 스팸인지 아닌지를 판단하거나, 환자가 특정 질병을 가지고 있는지 여부를 예측하는 경우\n",
    "- **주요 알고리즘**:\n",
    "    - 로지스틱 회귀(Logistic Regression) * 메인\n",
    "    - 서포트 벡터 머신(SVM) * 메인\n",
    "    - 결정 트리(Decision Trees)\n",
    "    - 랜덤 포레스트(Random Forest)\n",
    "    - 인공 신경망(Artificial Neural Networks)\n",
    "\n",
    "### 다중 분류 (Multi-Class Classification)\n",
    "\n",
    "- **정의**: 데이터 포인트를 두 개 이상의 클래스 중 하나로 분류하는 과정입니다. \n",
    "    **각 클래스는 서로 EXCLUSIVE**\n",
    "- **예시**: 사진에 나타난 동물의 종류를 분류하거나, 뉴스 기사를 여러 카테고리로 분류하는 경우.\n",
    "- **주요 알고리즘**:\n",
    "    - 나이브 베이즈(Naive Bayes)\n",
    "    - K-최근접 이웃(K-Nearest Neighbors, K-NN)\n",
    "    - 결정 트리(Decision Trees)\n",
    "    - 랜덤 포레스트(Random Forest)\n",
    "    - 인공 신경망(Artificial Neural Networks)\n",
    "\n",
    "### **주의해야 할 점**\n",
    "\n",
    "1. **데이터 불균형**: 한 클래스의 데이터가 다른 클래스보다 훨씬 많은 경우, 모델이 다수 클래스에 편향되어 학습할 수 있습니다. 이를 해결하기 위해 오버 샘플링(Over Sampling), 언더 샘플링(Under Sampling), SMOTE 기법 등을 사용할 수 있습니다.\n",
    "2. **특성 선택**: 모든 특성이 유용한 것은 아니며, 때로는 일부 특성이 모델의 성능을 저하시킬 수 있습니다. 특성 선택 또는 차원 축소 기법을 사용하여 중요한 특성만을 선택해야 합니다.\n",
    "3. **모델 복잡도**: 너무 단순한 모델은 데이터의 복잡성을 잘 표현하지 못할 수 있고(과소적합), 너무 복잡한 모델은 훈련 데이터에 과적합될 위험이 있습니다. 적절한 모델 복잡도를 선택하는 것이 중요합니다.\n",
    "4. **성능 평가 지표**: 정확도(accuracy)만으로 모델의 성능을 평가하는 것은 오해의 소지가 있습니다. 특히 데이터 불균형이 있을 때는 정밀도(precision), 재현율(recall), F1 점수(F1 Score), AUC-ROC 곡선 등 다양한 지표를 함께 고려해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05470a",
   "metadata": {},
   "source": [
    "# 문제~~\n",
    "\n",
    "심장병 분류~ 신용평가 분류 문제 같은 경우는 어떤 지표를 고려 해야할까?\n",
    "\n",
    "### **심장병 분류 문제**\n",
    "\n",
    "심장병 분류 문제에서는 주로 환자가 심장병을 가지고 있는지 여부를 예측하는 모델을 만듭니다. 이 경우, 두 가지 중요한 지표를 주로 고려합니다:\n",
    "\n",
    "1. **민감도(Sensitivity, Recall)**: 실제로 심장병을 가진 사람들 가운데, 모델이 정확히 심장병이 있다고 예측한 비율입니다. 심장병과 같은 건강 문제에서는 실제 양성인 사례들을 놓치지 않는 것이 매우 중요하기 때문에 민감도가 특히 중요합니다.\n",
    "2. **특이성(Specificity)**: 심장병이 없는 사람들 중 모델이 정확히 심장병이 없다고 예측한 비율입니다. 높은 특이성은 건강한 사람을 심장병 환자로 잘못 분류하는 오류를 최소화합니다.\n",
    "\n",
    "### **신용평가 문제**\n",
    "\n",
    "신용평가 문제에서는 개인이나 기업의 신용도를 평가하여 그들이 대출을 상환할 능력이 있는지를 예측합니다. 이 경우, 주로 다음 두 가지 지표에 중점을 둡니다:\n",
    "\n",
    "1. **정밀도(Precision)**: 신용이 좋지 않다고 예측된 사람들 중 실제로 신용이 좋지 않은 사람의 비율입니다. 신용평가에서는 잘못된 신용 불량 예측으로 인한 금융적 손실을 최소화하는 것이 중요하기 때문에, 정밀도가 중요한 지표가 됩니다.\n",
    "2. **민감도(Sensitivity, Recall)** 또는 **특이성(Specificity)**: 여기서 선택은 목표와 비용-이익 분석에 따라 달라집니다. 신용평가 모델이 신용 불량자를 놓치는 것이 큰 손실을 초래한다면 민감도가 중요할 수 있고, 반대로 건전한 대출자를 신용 불량자로 잘못 분류하는 것이 더 큰 문제가 될 경우 특이성이 더 중요할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951ab8d",
   "metadata": {},
   "source": [
    "# **Confusion Matrix** : 오차 행렬\n",
    "\n",
    "![Untitled](https://velog.velcdn.com/images/zxxzx1515/post/6582b2de-e2c9-44b0-9c22-9d0609f7043e/image.png)\n",
    "\n",
    "- **True Positive (TP)**: 실제 Positive 클래스를 Positive로 올바르게 예측한 경우\n",
    "- **False Positive (FP)**: 실제 Negative 클래스를 잘못하여 Positive로 예측한 경우\n",
    "- **True Negative (TN)**: 실제 Negative 클래스를 Negative로 올바르게 예측한 경우\n",
    "- **False Negative (FN)**: 실제 Positive 클래스를 잘못하여 Negative로 예측한 경우\n",
    "\n",
    "- **정확도(Accuracy)**: 모든 예측 중 올바른 예측의 비율\n",
    "    - (*TP*+*TN*)/(*TP*+*TN*+*FP*+*FN*)\n",
    "- **정밀도(Precision)**: Positive로 예측된 것 중 실제로 Positive인 것의 비율\n",
    "    - *TP*/(*TP*+*FP*)\n",
    "- **재현율(Recall) 또는 민감도(Sensitivity)**: 실제 Positive 중 Positive로 올바르게 예측된 비율\n",
    "    - *TP*/(*TP*+*FN*)\n",
    "- **특이성(Specificity)**: 실제 Negative 중 Negative로 올바르게 예측된 비율\n",
    "    - *TN*/(*TN*+*FP*)\n",
    "- **F1 점수(F1 Score)**: 정밀도와 재현율의 조화 평균\n",
    "    - 2∗(*Precision*∗*Recall*)/(*Precision*+*Recall*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7246d4e",
   "metadata": {},
   "source": [
    "### 정확도(Accuracy)와 정밀도(Precision)는 분류 모델의 성능을 평가?할까? (외우자)\n",
    "\n",
    "### **정확도(Accuracy)**\n",
    "\n",
    "정확도는 모델이 올바르게 예측한 비율을 나타내며, 전체 데이터 세트에서 모델의 일반적인 성능을 평가\n",
    "\n",
    "**정확도를 중점적으로 보는 케이스:**\n",
    "\n",
    "- **균형 잡힌 데이터셋**: 클래스 간의 분포가 대체로 균등한 경우, 정확도는 모델 성능의 좋은 지표가 될 수 있습니다.\n",
    "- **비용/결과가 각 클래스에 대해 비슷한 경우**: 오분류가 발생했을 때의 비용이나 영향이 모든 클래스에서 대체로 비슷한 경우, 전체적인 정확도가 중요한 지표가 될 수 있습니다.\n",
    "\n",
    "### **정밀도(Precision)**\n",
    "\n",
    "정밀도는 Positive로 예측된 경우 중 실제로 Positive인 비율을 나타내며, False Positive(실제는 Negative이지만 Positive로 잘못 분류된 경우)의 수를 최소화하는 것이 중요할 때 사용됩니다\n",
    "\n",
    "**정밀도를 중점적으로 보는 케이스:**\n",
    "\n",
    "- **불균형 데이터셋**: 한 클래스의 샘플 수가 다른 클래스보다 훨씬 많은 경우, 특히 소수 클래스의 예측 정확성이 중요한 경우 정밀도가 더 중요해집니다.\n",
    "- **False Positive의 비용이 높은 경우**: 예를 들어, 스팸 메일 필터링에서 정상 이메일을 스팸으로 잘못 분류하는 것(즉, 중요한 이메일을 놓칠 위험)의 비용이 스팸을 정상으로 분류하는 것보다 클 때, 정밀도가 중요한 지표가 됩니다.\n",
    "- **결정적인 예측이 필요한 경우**: 의료 진단, 금융 사기 탐지 등과 같이 오류가 심각한 결과를 초래할 수 있는 분야에서는 False Positive를 최소화하는 것이 매우 중요합니다.\n",
    "\n",
    "### **상황에 따른 선택**\n",
    "\n",
    "- **재현율(Recall) 또는 민감도**: 실제 Positive 중에서 모델이 얼마나 잘 예측했는지를 나타내며, False Negative(실제는 Positive이지만 Negative로 잘못 분류된 경우)를 최소화하는 것이 중요할 때 사용됩니다. 예를 들어, 암 진단에서 실제 암 환자를 놓치지 않는 것이 중요하므로 재현율이 중요한 지표가 됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
